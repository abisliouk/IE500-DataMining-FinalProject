{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\masam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\masam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peformance using Random Forest\n",
      "Accuracy: 0.6359111507317435\n",
      "F1-score: 0.6277655228348183\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# from sklearnex import patch_sklearn\n",
    "# patch_sklearn()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from data_prep import add_artists_as_features\n",
    "import nltk\n",
    "# Need to download stopwords and punkt to use the add_artists_as_features function\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "pd.options.display.max_columns = 200\n",
    "\n",
    "songs = pd.read_csv('../data/spotify_simplified.csv', index_col=[0])\n",
    "songs_data = add_artists_as_features(songs, 2000)\n",
    "songs_data = songs_data.drop(columns = [\"track_id\", \"artists\", \"album_name\", \"track_name\", \"track_genre\"])\n",
    "genres = songs[\"track_genre\"]\n",
    "# Numerically encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_genres = label_encoder.fit_transform(genres)\n",
    "# Using stratify might help because we have an imbalanced dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(songs_data, encoded_genres, test_size=0.3, \n",
    "                                                    stratify=encoded_genres, shuffle=True, random_state=100)\n",
    "# Train model\n",
    "model = RandomForestClassifier(max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=300)\n",
    "model.fit(X_train, y_train)\n",
    "# Evaluate model\n",
    "predictions = model.predict(X_test)\n",
    "base_accuracy = accuracy_score(y_test, predictions)\n",
    "base_f1_weighted = f1_score(y_test, predictions, average='weighted')\n",
    "print(\"Peformance using Random Forest\")\n",
    "print(f\"Accuracy: {base_accuracy}\")\n",
    "print(f\"F1-score: {base_f1_weighted}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     ambient       0.67      0.66      0.66      1820\n",
      "    children       0.65      0.73      0.69       873\n",
      "   classical       0.59      0.83      0.69       797\n",
      "      comedy       0.74      0.91      0.81       297\n",
      "     country       0.52      0.76      0.62       871\n",
      "         edm       0.65      0.32      0.43      3268\n",
      "    european       0.31      0.45      0.37      1157\n",
      "        folk       0.71      0.28      0.40      2122\n",
      "     hip-hop       0.35      0.63      0.45       481\n",
      "       latin       0.63      0.59      0.61      2672\n",
      "       metal       0.53      0.86      0.65      1800\n",
      "         pop       0.58      0.45      0.51      1891\n",
      "      reggae       0.22      0.62      0.33       738\n",
      "        rock       0.60      0.24      0.34      3045\n",
      "  show-tunes       0.26      0.66      0.38       521\n",
      "       sleep       0.76      0.99      0.86       299\n",
      "      techno       0.68      0.79      0.73      2401\n",
      "       world       0.54      0.49      0.51      1869\n",
      "\n",
      "    accuracy                           0.54     26922\n",
      "   macro avg       0.55      0.62      0.56     26922\n",
      "weighted avg       0.59      0.54      0.53     26922\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(y_test, predictions, target_names=list(label_encoder.classes_))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sleep</td>\n",
       "      <td>0.856729</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comedy</td>\n",
       "      <td>0.814480</td>\n",
       "      <td>990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>techno</td>\n",
       "      <td>0.729015</td>\n",
       "      <td>8002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>classical</td>\n",
       "      <td>0.688645</td>\n",
       "      <td>2655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>children</td>\n",
       "      <td>0.687163</td>\n",
       "      <td>2911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ambient</td>\n",
       "      <td>0.660942</td>\n",
       "      <td>6066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>metal</td>\n",
       "      <td>0.654515</td>\n",
       "      <td>5999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>country</td>\n",
       "      <td>0.617041</td>\n",
       "      <td>2902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>latin</td>\n",
       "      <td>0.606154</td>\n",
       "      <td>8908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>world</td>\n",
       "      <td>0.510376</td>\n",
       "      <td>6230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pop</td>\n",
       "      <td>0.509630</td>\n",
       "      <td>6305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hip-hop</td>\n",
       "      <td>0.447717</td>\n",
       "      <td>1604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>edm</td>\n",
       "      <td>0.431052</td>\n",
       "      <td>10894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>folk</td>\n",
       "      <td>0.400540</td>\n",
       "      <td>7072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>show-tunes</td>\n",
       "      <td>0.376227</td>\n",
       "      <td>1737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>european</td>\n",
       "      <td>0.368627</td>\n",
       "      <td>3858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rock</td>\n",
       "      <td>0.340994</td>\n",
       "      <td>10149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>reggae</td>\n",
       "      <td>0.326473</td>\n",
       "      <td>2460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         genre  f1-score  count\n",
       "0        sleep  0.856729    998\n",
       "1       comedy  0.814480    990\n",
       "2       techno  0.729015   8002\n",
       "3    classical  0.688645   2655\n",
       "4     children  0.687163   2911\n",
       "5      ambient  0.660942   6066\n",
       "6        metal  0.654515   5999\n",
       "7      country  0.617041   2902\n",
       "8        latin  0.606154   8908\n",
       "9        world  0.510376   6230\n",
       "10         pop  0.509630   6305\n",
       "11     hip-hop  0.447717   1604\n",
       "12         edm  0.431052  10894\n",
       "13        folk  0.400540   7072\n",
       "14  show-tunes  0.376227   1737\n",
       "15    european  0.368627   3858\n",
       "16        rock  0.340994  10149\n",
       "17      reggae  0.326473   2460"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_predicitons_df(y_test, predictions, class_names):\n",
    "    # Get more detailed performance information for each class\n",
    "    f1 = f1_score(y_test, predictions, average=None)\n",
    "    class_to_f1 = dict(zip(class_names, f1))\n",
    "    # Sort f1-score in descending order\n",
    "    class_to_f1 = dict(sorted(class_to_f1.items(), key=lambda item: item[1], reverse=True))\n",
    "    grouped_by_genre = songs.groupby(['track_genre']).size()\n",
    "    genre_count = grouped_by_genre.sort_values(ascending=False)\n",
    "    count = list()\n",
    "    for genre in class_to_f1.keys():\n",
    "        count.append(genre_count[genre])\n",
    "    predictions_df = pd.DataFrame([], columns=['genre', 'f1-score', 'count'])\n",
    "    predictions_df['genre'] = class_to_f1.keys()\n",
    "    predictions_df['f1-score'] = class_to_f1.values()\n",
    "    predictions_df['count'] = count\n",
    "    return predictions_df\n",
    "\n",
    "predictions_df = generate_predicitons_df(y_test, predictions, label_encoder.classes_)\n",
    "display(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_confusion_matrix(conf_matrix, class_names):\n",
    "    cm_df = pd.DataFrame(conf_matrix, index=class_names, columns=class_names)\n",
    "    heatmap = sns.heatmap(cm_df, annot=True, fmt='d', annot_kws={\"size\": 14})\n",
    "    heatmap.set(xlabel='Predicted class', ylabel='True class')\n",
    "    return heatmap\n",
    "\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "heatmap = plot_confusion_matrix(cm, label_encoder.classes_)\n",
    "plt.figure(figsize=[10, 30])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peformance using undersampling\n",
      "Accuracy: 0.5401\n",
      "F1: 0.5294\n"
     ]
    }
   ],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=100)\n",
    "sampler = RandomUnderSampler()\n",
    "pipeline = Pipeline([('balancing', sampler), ('classifier', model)])\n",
    "pipeline.fit(X_train, y_train)\n",
    "predictions = pipeline.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "f1_weighted = f1_score(y_test, predictions, average='weighted')\n",
    "print(\"Peformance using undersampling\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1: {f1_weighted:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance using oversampling\n",
      "Accuracy: 0.5384\n",
      "F1: 0.5285\n"
     ]
    }
   ],
   "source": [
    "pipeline.named_steps['balancing'] = RandomOverSampler()\n",
    "pipeline.fit(X_train, y_train)\n",
    "predictions = pipeline.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "f1_weighted = f1_score(y_test, predictions, average='weighted')\n",
    "# predictions = cross_val_predict(pipeline, songs_data_modified, encoded_genres, cv=cv, n_jobs=-1)\n",
    "# accuracy = accuracy_score(encoded_genres, predictions)\n",
    "# f1_weighted = f1_score(encoded_genres, predictions, average='weighted')\n",
    "print(\"Performance using oversampling\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1: {f1_weighted:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment conclusion:\n",
    "_Under and over sampling hinder the performace of the random forest_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
